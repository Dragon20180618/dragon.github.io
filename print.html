<!DOCTYPE HTML>
<html lang="en" class="light" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>DailyNotes</title>
        <meta name="robots" content="noindex">


        <!-- Custom HTML head -->
        
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->

    </head>
    <body class="sidebar-visible no-js">
    <div id="body-container">
        <!-- Provide site root to javascript -->
        <script>
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('light')
            html.classList.add(theme);
            var body = document.querySelector('body');
            body.classList.remove('no-js')
            body.classList.add('js');
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            var body = document.querySelector('body');
            var sidebar = null;
            var sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
            }
            sidebar_toggle.checked = sidebar === 'visible';
            body.classList.remove('sidebar-visible');
            body.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded "><a href="内存使用情况检查.html"><strong aria-hidden="true">1.</strong> 内存使用情况检查</a></li><li class="chapter-item expanded "><a href="神威Fortran样例.html"><strong aria-hidden="true">2.</strong> 神威Fortran样例</a></li><li class="chapter-item expanded "><a href="cblas_dgemm参数详解.html"><strong aria-hidden="true">3.</strong> cblas_dgemm参数详解</a></li><li class="chapter-item expanded "><a href="cuda.html"><strong aria-hidden="true">4.</strong> CUDA</a></li><li class="chapter-item expanded "><a href="debug-fortran-in-vscode.html"><strong aria-hidden="true">5.</strong> debug-fortran-in-vscode</a></li><li class="chapter-item expanded "><a href="gpt-3-5-turbo接口调用方法.html"><strong aria-hidden="true">6.</strong> gpt-3.5-turbo接口调用方法</a></li><li class="chapter-item expanded "><a href="make_unique_with_cuda.html"><strong aria-hidden="true">7.</strong> make_unique_with_cuda</a></li><li class="chapter-item expanded "><a href="makefile-wildcard.html"><strong aria-hidden="true">8.</strong> makefile-wildcard</a></li><li class="chapter-item expanded "><a href="MPI_CART使用方法.html"><strong aria-hidden="true">9.</strong> MPI_CART使用方法</a></li><li class="chapter-item expanded "><a href="OpenBlas-Make-Test.html"><strong aria-hidden="true">10.</strong> OpenBlas-Make-Test</a></li><li class="chapter-item expanded "><a href="pytorch-geometric安装.html"><strong aria-hidden="true">11.</strong> pytorch-geometric安装</a></li><li class="chapter-item expanded "><a href="x11-with-color.html"><strong aria-hidden="true">12.</strong> x11-with-color</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <!-- Track and set sidebar scroll position -->
        <script>
            var sidebarScrollbox = document.querySelector('#sidebar .sidebar-scrollbox');
            sidebarScrollbox.addEventListener('click', function(e) {
                if (e.target.tagName === 'A') {
                    sessionStorage.setItem('sidebar-scroll', sidebarScrollbox.scrollTop);
                }
            }, { passive: true });
            var sidebarScrollTop = sessionStorage.getItem('sidebar-scroll');
            sessionStorage.removeItem('sidebar-scroll');
            if (sidebarScrollTop) {
                // preserve sidebar scroll position when navigating via links within sidebar
                sidebarScrollbox.scrollTop = sidebarScrollTop;
            } else {
                // scroll sidebar to current active section when navigating via "next/previous chapter" buttons
                var activeSection = document.querySelector('#sidebar .active');
                if (activeSection) {
                    activeSection.scrollIntoView({ block: 'center' });
                }
            }
        </script>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">DailyNotes</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <p>date: 2023-12-22 09:44:42</p>
<p>tags: malloc memory check</p>
<ul>
<li>代码</li>
</ul>
<pre><code class="language-C++">#include &lt;iostream&gt;
#include &lt;malloc.h&gt;
using namespace std;

int main()
{
  // 调用mallinfo()函数获取堆内存的统计信息
  struct mallinfo mi;
  int *a[10];
  size_t old=0;
  size_t delta=0;
  for(int i=0;i&lt;10;i++)
  {
    a[i]=0;
    a[i] = (int*)malloc(40000000);
    mi = mallinfo();
    // 计算堆内存的已使用大小
    size_t heap_used = mi.arena + mi.hblkhd;
    // 打印堆内存的统计信息
    delta = heap_used - old;
    cout &lt;&lt; "heap_used: " &lt;&lt; heap_used &lt;&lt; " bytes| delta: " &lt;&lt; delta &lt;&lt; endl;
    cout &lt;&lt; mi.arena&lt;&lt;" "&lt;&lt;mi.ordblks&lt;&lt;" "&lt;&lt;mi.smblks&lt;&lt;" "&lt;&lt;mi.hblks&lt;&lt;endl;
    old = heap_used;
  }
  return 0;
}
</code></pre>
<ul>
<li>输出结果</li>
</ul>
<pre><code class="language-log">heap_used: 40214528 bytes| delta: 40214528
212992 1 0 1
heap_used: 80216064 bytes| delta: 40001536
212992 1 0 2
heap_used: 120217600 bytes| delta: 40001536
212992 1 0 3
heap_used: 160219136 bytes| delta: 40001536
212992 1 0 4
heap_used: 200220672 bytes| delta: 40001536
212992 1 0 5
heap_used: 240222208 bytes| delta: 40001536
212992 1 0 6
heap_used: 280223744 bytes| delta: 40001536
212992 1 0 7
heap_used: 320225280 bytes| delta: 40001536
212992 1 0 8
heap_used: 360226816 bytes| delta: 40001536
212992 1 0 9
heap_used: 400228352 bytes| delta: 40001536
212992 1 0 10
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><p>date: 2023-03-30 15:26:14</p>
<p>tags: SACA FORTRAN CRTS</p>
<h3 id="主核代码-mainf90"><a class="header" href="#主核代码-mainf90">主核代码 main.f90</a></h3>
<pre><code class="language-fortran">program main
    use utility
    implicit none
    integer :: i, j
    integer :: N = 10
    integer, pointer :: matrix_A(:,:)
    integer, pointer :: vector_B(:)
    integer, pointer :: vector_C(:)
    type(ParaType)::para
    integer, external :: slave_func
    allocate(matrix_A(N,N), vector_B(N), vector_C(N))
    para%N = N
    para%matrix_A =&gt; matrix_A
    para%vector_B =&gt; vector_B
    para%vector_C =&gt; vector_C
    print *, "A and B"
    do i = 1, N
        do j = 1, N
            matrix_A(j,i) = floor(11*rand())
            write(*, "(I4)", advance="no") matrix_A(j,i)
        end do
        vector_B(i) = floor(11*rand())
        write(*, "(I4)", advance="no") vector_B(i)
        print *
    end do
    call CRTS_Init()
    call CRTS_athread_spawn(slave_func, para)
    call CRTS_athread_join()
    print *, "C = A.dot(B)"
    do i = 1, N
        write(*, "(I4)", advance="no") vector_C(i)
    end do
    print *
end program main
</code></pre>
<h3 id="工具模块-utilityf90"><a class="header" href="#工具模块-utilityf90">工具模块 utility.f90</a></h3>
<pre><code class="language-fortran">module utility
    implicit none
    type, public :: ParaType
        integer :: N
        integer,pointer :: matrix_A(:,:)
        integer,pointer :: vector_B(:)
        integer,pointer :: vector_C(:)
    end type ParaType
interface
    integer function CRTS_smng_get_tid()
    end function CRTS_smng_get_tid
end interface
contains
end module utility
</code></pre>
<h3 id="从核代码-slavef90"><a class="header" href="#从核代码-slavef90">从核代码 slave.f90</a></h3>
<pre><code class="language-fortran">subroutine slave_func(para)
    use utility
    implicit none
    type(ParaType), intent(in) :: para
    integer :: N
    integer, pointer :: matrix_A(:,:)
    integer, pointer :: vector_B(:)
    integer, pointer :: vector_C(:)
    integer :: i, j
    integer :: myid
    integer :: tmp
    myid = CRTS_smng_get_tid()
    N = para%N
    if(myid &lt; N) then
        matrix_A =&gt; para%matrix_A
        vector_B =&gt; para%vector_B
        vector_C =&gt; para%vector_C
        tmp = 0
        do i = 1,N
            tmp = tmp + matrix_A(i, myid+1) * vector_B(i)
        end do
        vector_C(myid+1) = tmp
    end if
end subroutine slave_func
</code></pre>
<h3 id="makefile"><a class="header" href="#makefile">Makefile</a></h3>
<pre><code class="language-makefile">FC = swgfortran
main: main.o slave.o utility.o
	$(FC) -mhybrid $^ -o $@
main.o: main.f90 utility.o
	$(FC) -mhost -c $&lt;
slave.o: slave.f90 utility.o
	$(FC) -mslave -c slave.f90
utility.o: utility.f90
	$(FC) -c $&lt;
run:
	bsub -I -b -q q_linpack -cgsp 64 -n 1 ./main
clean:
	rm -rf *.o main *.mod
</code></pre>
<h3 id="程序输出"><a class="header" href="#程序输出">程序输出</a></h3>
<p><img src="./%E7%A5%9E%E5%A8%81Fortran%E6%A0%B7%E4%BE%8B/1680161547625.png" alt="1680161547625" /></p>
<div style="break-before: page; page-break-before: always;"></div><p>date: 2022-08-22 14:34:18</p>
<p>tags:</p>
<h1 id="cblas_dgemm参数详解"><a class="header" href="#cblas_dgemm参数详解">cblas_dgemm参数详解</a></h1>
<p>[dragon](mailto: wauqas@gmail.com) 22-8-15</p>
<h2 id="代码"><a class="header" href="#代码">代码</a></h2>
<pre><code class="language-c">#include &lt;cblas.h&gt;
#include &lt;stdio.h&gt;

int main()
{
  int i = 0;
  double A[6] = {1.0, 10.0, 20.0, 30.0, 40.0, 50.0};
  double B[6] = {1.0, 10.0, 20.0, 30.0, 40.0, 60.0};
  double C[9] = {.5, .5, .5, .5, .5, .5, .5, .5, .5};
  cblas_dgemm(CblasColMajor, CblasNoTrans, CblasTrans, \
              3, 3, 2, 1, A, 3, B, 3, 0, C, 3);
  for (int j = 0; j &lt; 3; j++)
  {
    for (i = 0; i &lt; 3; i++)
      printf("%lf ", C[i*3+j]);
    printf("\n");
  }
  return 0;
}
</code></pre>
<h2 id="解释"><a class="header" href="#解释">解释</a></h2>
<pre><code class="language-c">void cblas_dgemm(
    	OPENBLAS_CONST enum CBLAS_ORDER Order, //行列主序
        OPENBLAS_CONST enum CBLAS_TRANSPOSE TransA, //矩阵A转置
        OPENBLAS_CONST enum CBLAS_TRANSPOSE TransB, //矩阵B转置
        OPENBLAS_CONST blasint M, //op(A)的行数
        OPENBLAS_CONST blasint N, //op(B)的列数
        OPENBLAS_CONST blasint K, //op(A)的列数和op(B)的行数
        OPENBLAS_CONST double alpha, //A的缩放
        OPENBLAS_CONST double *A, //matrix A
        OPENBLAS_CONST blasint lda, //A的第一维度,跟主序有关
       	OPENBLAS_CONST double *B, //matrix B
        OPENBLAS_CONST blasint ldb, //B的第一维度
        OPENBLAS_CONST double beta, //C 的缩放
        double *C, //matrix C
        OPENBLAS_CONST blasint ldc //C的第一维度
);
</code></pre>
<p>最终结果为$C=alpha*op(A)<em>op(B)+beta</em>C$</p>
<div style="break-before: page; page-break-before: always;"></div><p>date: 2022-08-22 16:39:25</p>
<p>tags: cuda</p>
<h1 id="cuda"><a class="header" href="#cuda">CUDA</a></h1>
<p>cuda program kernel function:</p>
<p><code>__global__ void functionName(){}</code></p>
<p>or</p>
<p><code>void __global__ functionName(){}</code></p>
<hr />
<h3 id="hello-world"><a class="header" href="#hello-world">Hello World</a></h3>
<h4 id="hellocu"><a class="header" href="#hellocu">Hello.cu</a></h4>
```c++
#include<stdio.h>
__global__ void GPU_print(){
    printf("Hello World\n");
}
int main(int argc,char **argv){
    GPU_print<<<2,2>>>();
    cudaDeviceSynchronize();
    return 0;
}
```
<p>Compile:</p>
<pre><code class="language-nvcc">nvcc Hello.cu -o Hello
</code></pre>
<p>Execute:</p>
<pre><code class="language-c">./Hello
</code></pre>
<p>Result:</p>
<p><code>Hello World</code></p>
<p><code>Hello World</code></p>
<p><code>Hello World</code></p>
<p><code>Hello World</code></p>
<p>why?  &lt;&lt;&lt;2,2&gt;&gt;&gt;</p>
<hr />
<p>CUDA kernel run in Device. We should realise the differences of Host datas with Device datas.</p>
<p>Let's see the CUDA functions !</p>
<p>cudaMalloc(</p>
<pre><code>					(void\*\*)&amp;ptr,  int \*ptr -&gt; (void\*\*)&amp;ptr 

					size, sizeof(ptr_type);

				)
</code></pre>
<p>ptr will get some places from Device</p>
<p>cudaMemcpy(</p>
<pre><code>				dst, date to dst

				src, date from src

				size, how many bytes

				kind,where to where(cudaMemcpyHostToDevice,cudaMemcpyDeviceToHost and ......)

				)
</code></pre>
<p>cudaDeviceSynchronize()</p>
<p>Wait operate in Device finish</p>
<hr />
<p>GPU has lot's of same things with CPU</p>
<p>different kinds of memory is one of the same things.</p>
<h5 id="dynamic-common-element"><a class="header" href="#dynamic-common-element">dynamic common Element</a></h5>
```c++
double *a;
int M=1000;
cudaMalloc((void**)&a,M);
cudaMemcpy(....);
kernel<<<gridSize,blockSize>>>(a);
```
<h5 id="static-global-element"><a class="header" href="#static-global-element">static global Element</a></h5>
global and static
<pre><code class="language-c++">__device__ double a[5];
__device__ int b;
</code></pre>
<p>compiler should know the size of static global Element,and we need't be used by arg-way</p>
<p>needn't <code>kernel&lt;&lt;&lt;1,1&gt;&gt;&gt;(a);</code></p>
<h5 id="constant-element-by-arg-way"><a class="header" href="#constant-element-by-arg-way">constant Element by arg-way</a></h5>
```c++
int a=1;
kernel<<<1,1>>>(a);
```
<p>read-only and max size is 4KB</p>
<h5 id="constant-element-by-__constant__"><a class="header" href="#constant-element-by-__constant__">constant Element by __constant__</a></h5>
```c++
__constant__ int a=1;
```
<p>read-only and max size is 64 in most NVIDIA GPU</p>
<p>How to copy datas from/to constant Element ?</p>
<p>cudaMemcpyFromSymbol(</p>
<pre><code>											dst, datas to dst

											src, datas from src

											copykind, cudaMemcpyDeviceToHost

											)
</code></pre>
<p>cudaMemcpyToSymbol(</p>
<pre><code>										dst, datas to dst

										src, datas from src

										copykind, cudaMemcpyHostToDevice

										)
</code></pre>
<h5 id="dynamic-shared-memory"><a class="header" href="#dynamic-shared-memory">dynamic shared memory</a></h5>
```c++
__global__ void kernel(){
	int n=10;
	__shared__ int a[n];
}
```
<p>read and write, 64KB per block. same block with same shared memory value</p>
<h5 id="static-shared-memory"><a class="header" href="#static-shared-memory">static shared memory</a></h5>
outside:
<p><code>kernel&lt;&lt;&lt;1,1,sharedMemorySize&gt;&gt;&gt;()</code></p>
<p>inside:</p>
<p><code>extern __shared__  double a[]</code></p>
<p>not *a, pointer isn't array</p>
<h5 id="register-memory"><a class="header" href="#register-memory">register memory</a></h5>
fast and small
<pre><code class="language-c++">__global__ void kernel(){
    int a=1;
    const int b=1;
}
</code></pre>
<h5 id="dynamic-unified-memory"><a class="header" href="#dynamic-unified-memory">dynamic unified memory</a></h5>
```c++
double *x,*y;
const int M=sizeof(double)*10000;
cudaMallocManaged((void**)&x,M);
cudaMallocManaged((void**)&y,M);
*x=1;
*y=2;
kernel<<<gridSize,blockSize>>>(x,y);
```
<h5 id="static-unified-memory"><a class="header" href="#static-unified-memory">static unified memory</a></h5>
```c++
__device__ __managed__ int ret[1000];
__device__ __managed__ int a;
int main(){
    kernel<<<gridSize,blockSize>>>();
    cudaSynchronize();
    printf("%d\n",a);
}
```
<h5 id="free-memory"><a class="header" href="#free-memory">Free Memory</a></h5>
`cudaFree(void* ptr)`
<hr />
<h3 id="atoi-operate"><a class="header" href="#atoi-operate">Atoi operate</a></h3>
look like synchronize, but really without synchronize
<p><a href="%E5%8E%9F%E5%AD%90%E5%87%BD%E6%95%B0%E8%A1%A8.html">Table</a></p>
<h3 id="cuda-stream"><a class="header" href="#cuda-stream">CUDA Stream</a></h3>
Let's see the functions!
<p><strong>type:</strong> cudaStream_t  stream</p>
<p>cudaStreamCreate(&amp;stream)</p>
<p>cudaStreamDestory(stream)</p>
<p>cudaStreamSynchronize(stream), wait stream finish</p>
<p>cudaStreamQuery(stream), check stream finish or not, <strong>cudaSuccess</strong> or <strong>cudaErrorNotReady</strong></p>
<p><strong>run in stream :</strong> <code>kernel&lt;&lt;&lt;gridSize, blockSize,shared_size,stream&gt;&gt;&gt;();</code></p>
<p>cudaMemcpyAsync(</p>
<pre><code>								void *dst

								const void *src

								size_t count

								enum cudaMemcpyKind kind

								cudaStream_t stream, if you want to use default stream, by 0

								)
</code></pre>
<p>which datas can be MemcpyAsync ?</p>
<p><code>cudaMallocHost(void**ptr, size_t size)</code></p>
<p><code>cudaHostAlloc(void**ptr, size_t size,size_t flag)</code></p>
<p>if flag==cudaHostAllocDefault, cudaMallocHost equal to cudaHostAlloc</p>
<p><strong>Free:</strong><code>cudaFreeHost(void* ptr)</code></p>
<div style="break-before: page; page-break-before: always;"></div><p>date: 2022-08-23 14:52:12</p>
<p>tags: vscode fortran debug</p>
<p><strong>please make sure you have gdb and gfortran</strong></p>
<ul>
<li>
<p>launch.json</p>
<pre><code class="language-json">{
    "version": "0.0.1",
    "configurations": [
        {
            "name": "Fortran Launch (GDB)",
            "type": "cppdbg",
            "request": "launch",
            "targetArchitecture": "x64",
            "program": "${workspaceRoot}\\${fileBasenameNoExtension}.exe",
            "miDebuggerPath": "D:\\cygwin64\\bin\\gdb.exe",
            "args": [],
            "stopAtEntry": false,
            "cwd": "${workspaceRoot}",
            "externalConsole": true,
            "preLaunchTask": "gfortran"
        }
    ] }
</code></pre>
<p>"miDebuggerPath" insert your gdb full path.</p>
</li>
<li>
<p>tasks.json</p>
<pre><code class="language-json">{
    "tasks": [
        {
            "label": "gfortran",
            "type": "shell",
            "command": "gfortran -o ${fileBasenameNoExtension}.exe  ${fileBasename} -g",
            "options": {
                "cwd": "${workspaceFolder}"
            },
            "group": {
                "kind": "build",
                "isDefault": true
            }            
        },
  ],
    "version": "2.0.0"
}
</code></pre>
</li>
</ul>
<p><strong>configure finish</strong></p>
<h2 id="method-of-using"><a class="header" href="#method-of-using">method of using</a></h2>
<p><img src="./debug-fortran-in-vscode/1661237821036.png" alt="1661237821036" /></p>
<p>there are three or more ways to debug the example code.</p>
<p>you can also set some break points.</p>
<p>Wish you best.</p>
<div style="break-before: page; page-break-before: always;"></div><p>date: 2023-03-02 15:12:08</p>
<p>tags: gpt python</p>
<p>在3月1日刚发布的gpt-3.5-turbo，学习一下它的调用方法</p>
<ul>
<li>以post方法调用</li>
</ul>
<pre><code class="language-python">import requests

url = 'https://api.openai.com/v1/chat/completions'

Question = input("Question:")

data = {"model": "gpt-3.5-turbo","messages": [{"role": "user", "content": Question}]}

headers = {
    'Authorization': 'Bearer sk-' #后面输入自己的api-key
}

response = requests.post(url, json=data, headers=headers)

if response.status_code == 200:
    x = response.json()
    print(x['choices'][0]['message']['content'])
else:
    print("error:",response.status_code)
</code></pre>
<p>启动程序之后输入问题然后发送请求。</p>
<ul>
<li>以python openai模块调用</li>
</ul>
<pre><code class="language-python">import openai
openai.api_key="sk-"
message=[]
while(True):
    Q = input("user:")
    message.append({"role":"user","content":Q})
    com=openai.ChatCompletion.create(model="gpt-3.5-turbo",messages=message)
    message.append({"role":"assistant","content":com.choices[0].message.content})
    print("assistant:",com.choices[0].message.content)
</code></pre>
<p>跟上面的代码功能有所不同的是，这个可以联系上下文，类似网页上与chatgpt对话的过程。
用户的角色设置为user，ai的角色设置为assistant。
目前不管是直接post请求还是用python的openai模块，都不需要连接外网，平时使用较为方便。</p>
<h2 id="程序大小问题"><a class="header" href="#程序大小问题">程序大小问题</a></h2>
<p>在实际测试后发现：直接用post的版本，生成exe的大小在6M左右。而使用openai模块的版本，因为要打包openai模块，大小在70M左右。所以还是建议用post的版本
以下程序也可实现联系上下文</p>
<pre><code class="language-python">import requests

url = 'https://api.openai.com/v1/chat/completions'

headers = {
    'Authorization': 'Bearer sk-'
}

message=[]

while(True):
    Q = input("user:")
    message.append({"role":"user","content":Q})
    data = {"model": "gpt-3.5-turbo","messages": message}
    response = requests.post(url, json=data, headers=headers)
    if response.status_code == 200:
        x = response.json()
        print("assistant:",x['choices'][0]['message']['content'])
        message.append({"role":"assistant","content":x['choices'][0]['message']['content']})
    else:
        print("error:",response.status_code)
        break
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><p>date: 2022-08-23 11:10:23</p>
<p>tags: cuda cpp</p>
<h1 id="make_unique_with_cuda"><a class="header" href="#make_unique_with_cuda">make_unique_with_cuda</a></h1>
<pre><code class="language-c++">#include "stdio.h"
#include &lt;memory&gt;
namespace cuda
{
    template &lt;typename T&gt;
    [[nodiscard]] static auto malloc(std::size_t const size)
    {
        //nodiscard implies must use it return value, or will encounter an error
        static T *d{nullptr};
        cudaMalloc(&amp;d, sizeof(T) * size);
        return d;
    }
    template &lt;typename T&gt;
    static void free(T *ptr)
    {
        if (ptr)
        {
            cudaFree(ptr);
            ptr=nullptr;
        }
    }
    template &lt;typename T&gt;
    [[nodiscard]] static auto makeUnique(std::size_t size)
    {
        return std::unique_ptr&lt;T[], decltype(&amp;free&lt;T&gt;)&gt; { malloc&lt;T&gt;(size), free&lt;T&gt; };
    }
} // namespace name
__global__ void kernel(float3 *d)
{
    int id = threadIdx.x;
    // d[id].x=d[id].y=d[id].z=id*1.1;
    printf("%g\t%g\t%g\n", d[id].x, d[id].y, d[id].z);
}
void showh(float3 *d)
{
    for (int id = 0; id &lt; 5; id++)
    {
        printf("%g\t%g\t%g\n", d[id].x, d[id].y, d[id].z);
    }
}
using namespace cuda;
int main(void)
{
    auto const count = 5;
    auto hp_points{std::make_unique&lt;float3[]&gt;(count)};
    for (int i = 0; i &lt; count; i++)
    {
        hp_points[i].x=i*1.1;
        hp_points[i].y=i*1.1;
        hp_points[i].z=i*1.1;
    }
    // showh(hp_points.get());
    auto dp_points{cuda::makeUnique&lt;float3&gt;(count)};
    cudaMemcpy(dp_points.get(),hp_points.get(), //get() will return unique ptr's address
    sizeof(float3)*count,cudaMemcpyHostToDevice);
    kernel&lt;&lt;&lt;1,5&gt;&gt;&gt;(dp_points.get());
    cudaDeviceSynchronize();
    dp_points.~unique_ptr();
    return 0;
}
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><p>date: 2022-11-17 14:36:31</p>
<p>tags: makefile wildcard filter-out patsubst</p>
<h2 id="文件列表"><a class="header" href="#文件列表">文件列表</a></h2>
<pre><code class="language-shell">main.f90
makefile
sub1.f90
sub2.f90
sub3.f90
</code></pre>
<h2 id="makfile代码"><a class="header" href="#makfile代码">makfile代码</a></h2>
<pre><code class="language-makefile">main = main.f90

SRC = $(wildcard *.f90)

SRC := $(filter-out $(main),$(SRC))

SRC := $(patsubst %.f90, %.o, $(SRC))

main:

    echo $(SRC)
</code></pre>
<ul>
<li>wildcard
在对变量调用时，保持通配符特性</li>
<li>filter-out
过滤器，删除后面跟的第一个参数</li>
<li>patsubst
将变量中元素根据参数替换，上述代码将所有.f90替换为.o</li>
</ul>
<h2 id="执行结果"><a class="header" href="#执行结果">执行结果</a></h2>
<pre><code class="language-shell">$&gt; make
echo  sub1.o  sub2.o  sub3.o
 sub1.o  sub2.o  sub3.o
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><p>date: 2023-03-13 15:50:12</p>
<p>tags:</p>
<h2 id="mpi_cart_create"><a class="header" href="#mpi_cart_create">MPI_Cart_Create</a></h2>
<p>将一维的通信空间转为多维</p>
<p>接口</p>
<pre><code class="language-fortran">subroutine MPI_Cart_shift(comm, direction, disp, rank_source, rank_dest)
        integer,intent(in)  ::comm, 		!通信域
        integer,intent(in)  ::direction,    !维度序号
        integer,intent(in)  ::disp,		   	!偏移量
  		integer,intent(out) ::rank_source,	!向本进程发送数据的进程 如果没有则为-1
  	    integer,intent(out) ::rank_dest		!本进程发送数据的目的进程 如果没有则为-1
end subroutine MPI_Cart_shift
</code></pre>
<h2 id="测试"><a class="header" href="#测试">测试</a></h2>
<ul>
<li>查看period对网络生成的影响</li>
</ul>
<pre><code class="language-fortran">program main
    use mpi
    integer ierr
    integer rank,size
    integer np_dim(2)
    logical period(2)
    integer mpi_world_cart
    integer src,dest
    np_dim=3
    period(1)=.false.
    period(2)=.true.
    call MPI_Init(ierr)
    call MPI_Cart_create( MPI_COMM_WORLD    &amp;
                            , 2                 &amp;
                            , np_dim            &amp;
                            , period            &amp;
                            , .false.           &amp;
                            , mpi_world_cart    &amp;
                            , ierr              &amp;
                            )
    call MPI_Comm_rank(mpi_world_cart,rank,ierr)
    call MPI_Comm_size(mpi_world_cart,size,ierr)
    call MPI_Cart_shift(mpi_world_cart, 0, 1, src, dest,ierr)
    call MPI_Finalize(ierr)
    print *,rank,"of",size,"|",src,"of",dest,"|",(ierr==0)
end program main
</code></pre>
<p>输出</p>
<pre><code class="language-shell">           6 of           9 |           3 of          -1 | T 
           1 of           9 |          -1 of           4 | T
           2 of           9 |          -1 of           5 | T
           0 of           9 |          -1 of           3 | T
           5 of           9 |           2 of           8 | T 以此条为例，5从2接收，发送到8
           4 of           9 |           1 of           7 | T
           3 of           9 |           0 of           6 | T
           7 of           9 |           4 of          -1 | T
           8 of           9 |           5 of          -1 | T
</code></pre>
<p>第一维度的period设置为.false.，导致网络在第一维度不是环状的，而是线性的；</p>
<p>第二维度的period设置为.true.，导致网络在第二维度是环状的，最后一个进程的下一个进程是第一个进程。</p>
<p>这种设置方式会产生一个类似圆柱形的结构，圆柱的底是头尾连接的，圆柱的高是头尾分离的。</p>
<p>因为MPI_Cart_shift选取的维度是第一维度，且period(1)==.false.，所以0~2进程的src为-1，6~8进程的dest为-1。</p>
<p>以下是period(1)==.true.时程序的输出。</p>
<pre><code class="language-shell">           0 of           9 |           6 of           3 | T
           6 of           9 |           3 of           0 | T
           8 of           9 |           5 of           2 | T 8从5接受，发送到2
           7 of           9 |           4 of           1 | T
           1 of           9 |           7 of           4 | T
           3 of           9 |           0 of           6 | T
           2 of           9 |           8 of           5 | T
           4 of           9 |           1 of           7 | T
           5 of           9 |           2 of           8 | T
</code></pre>
<p>MPI_Cart_Create函数的reorder参数是用来指定创建出来的Cartesian拓扑是否可以被重新排序的。具体来说，如果reorder参数被设置为1，那么MPI库就可以为了提高性能而重新排列进程的拓扑结构。如果reorder参数被设置为0，那么MPI库就必须按照进程的原始顺序来创建Cartesian拓扑结构。</p>
<p>当reorder参数被设置为1时，MPI库可以为了提高性能而重新排列进程的拓扑结构。例如，假设原始的进程布局如下所示：</p>
<pre><code class="language-text">0 1 2 3
4 5 6 7
8 9 10 11
</code></pre>
<p>如果reorder参数被设置为1，MPI库可以重新排列进程的拓扑结构，例如：</p>
<pre><code class="language-text">0 4 8 9
1 5 6 10
2 3 7 11
</code></pre>
<p>这样做的目的是为了使相邻的进程在物理空间中更接近，从而减少通信延迟。但是需要注意的是，重新排序进程的拓扑结构可能会影响到原始程序的正确性，因此在使用该特性时需要小心谨慎。</p>
<div style="break-before: page; page-break-before: always;"></div><p>date: 2022-08-25 09:17:16</p>
<p>tags: openblas</p>
<h1 id="openblas-make"><a class="header" href="#openblas-make">OpenBlas-Make</a></h1>
<h2 id="environment"><a class="header" href="#environment">environment:</a></h2>
<ul>
<li>redhat</li>
<li>gcc version 4.8.5 20150623 (Red Hat 4.8.5-36) (GCC)</li>
</ul>
<h2 id="build"><a class="header" href="#build">build</a></h2>
<pre><code class="language-shell">make CC=gcc FC=gfortran make_NB_JOBS=1
make install PREFIX=&lt;install_path&gt;
</code></pre>
<p>if you don't make with suffix <code>make_NB_JOBS</code>, and has a old lapack in you machine,</p>
<p>openblas will generate before included lapack built, And won't call the old lapack lib.</p>
<h2 id="test"><a class="header" href="#test">test</a></h2>
<pre><code class="language-c">#include &lt;cblas.h&gt;
#include &lt;stdio.h&gt;

int main()
{
  int i=0;
  double A[6] = {1.0,2.0,1.0,-3.0,4.0,-1.0};         
  double B[6] = {1.0,2.0,1.0,-3.0,4.0,-1.0};  
  double C[9] = {.5,.5,.5,.5,.5,.5,.5,.5,.5}; 
  cblas_dgemm(CblasColMajor, CblasNoTrans, CblasTrans,3,3,2,1,A, 3, B, 3,2,C,3);

  for(i=0; i&lt;9; i++)
    printf("%lf ", C[i]);
  printf("\n");
  return 0;
}
</code></pre>
<pre><code class="language-shell">$ gcc -I ~/OpenBLAS/include  -L ~/OpenBLAS/lib -lopenblas main.cpp -o solver
$ ./solver
11.000000 -9.000000 5.000000 -9.000000 21.000000 -1.000000 5.000000 -1.000000 3.000000
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><p>date: 2023-01-08 21:20:37</p>
<p>tags:</p>
<p>离线安装</p>
<blockquote>
<p>若计算机中的python版本为Python 3.6.8，需要安装python3.8.5</p>
<p><code>PyG is available for Python 3.7 to Python 3.10.</code></p>
</blockquote>
<h3 id="安装python385"><a class="header" href="#安装python385">安装Python3.8.5</a></h3>
<p>https://www.python.org/downloads/release/python-385/</p>
<p>tar.xz文件解压命令 <code>tar xf</code></p>
<p>进入解压后的文件，执行安装三部曲</p>
<pre><code class="language-shell">./configure --prefix=${HOME}/Python3.8.5
make
make install
</code></pre>
<p>修改.bashrc，这次不但要添加python目录到python，还需要加alias将/usr/bin/下的python3屏蔽</p>
<pre><code class="language-bash">#Python-3.8.5
export PATH=$PATH:${HOME}/Python3.8.5/bin
alias python3=${HOME}/Python3.8.5/bin/python3
</code></pre>
<p>检查版本</p>
<pre><code class="language-shell">[liyl@gpu-node1 ~]$ python3
Python 3.8.5 (default, Jan  5 2023, 14:09:20) 
[GCC 4.8.5 20150623 (Red Hat 4.8.5-44)] on linux
Type "help", "copyright", "credits" or "license" for more information.
&gt;&gt;&gt;
</code></pre>
<h3 id="安装wheel"><a class="header" href="#安装wheel">安装wheel</a></h3>
<pre><code class="language-bash">pip3 install wheel-0.37.1-py2.py3-none-any.whl --user
</code></pre>
<h3 id="安装numpy"><a class="header" href="#安装numpy">安装numpy</a></h3>
<p>https://pypi.org/project/numpy/1.23.5/#files
numpy-1.23.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl</p>
<p>安装包已经放到文档目录</p>
<pre><code class="language-bash">python3 -m pip install numpy-1.23.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl --user
</code></pre>
<p>--user： 安装到用户目录，不需要sudo权限，安装位置为**./.local/lib/python3.8/site-packages**</p>
<h3 id="安装typing_extensions"><a class="header" href="#安装typing_extensions">安装typing_extensions</a></h3>
<pre><code class="language-bash">python3 -m pip install typing_extensions-4.4.0-py3-none-any.whl --user
</code></pre>
<h3 id="安装pytorch"><a class="header" href="#安装pytorch">安装pyTorch</a></h3>
<p>http://download.pytorch.org/whl/torch_stable.html</p>
<p>torch-1.13.1+cpu-cp38-cp38-linux_x86_64.whl</p>
<pre><code class="language-bash">python3 -m pip install torch-1.13.1+cpu-cp38-cp38-linux_x86_64.whl --user
</code></pre>
<h3 id="注意事项"><a class="header" href="#注意事项">注意事项</a></h3>
<p><em><strong>安装要注意先后关系</strong></em></p>
<p>如果给你的安装包无法安装numpy或是pyTorch，首先检查python版本和主机所属平台，可以通过以下python代码实现查询</p>
<pre><code class="language-bash">python3 -m pip debug --verbose
</code></pre>
<p>我的运行结果：</p>
<pre><code>Compatible tags: 87
  cp38-cp38-manylinux2014_x86_64
  cp38-cp38-manylinux2010_x86_64
  cp38-cp38-manylinux1_x86_64
  cp38-cp38-linux_x86_64
  cp38-abi3-manylinux2014_x86_64
  cp38-abi3-manylinux2010_x86_64
  cp38-abi3-manylinux1_x86_64
  cp38-abi3-linux_x86_64
  cp38-none-manylinux2014_x86_64
  cp38-none-manylinux2010_x86_64
  cp38-none-manylinux1_x86_64
  cp38-none-linux_x86_64
  cp37-abi3-manylinux2014_x86_64
  cp37-abi3-manylinux2010_x86_64
  cp37-abi3-manylinux1_x86_64
  cp37-abi3-linux_x86_64
  cp36-abi3-manylinux2014_x86_64
  cp36-abi3-manylinux2010_x86_64
  cp36-abi3-manylinux1_x86_64
  cp36-abi3-linux_x86_64
  cp35-abi3-manylinux2014_x86_64
  cp35-abi3-manylinux2010_x86_64
  cp35-abi3-manylinux1_x86_64
  cp35-abi3-linux_x86_64
  cp34-abi3-manylinux2014_x86_64
  cp34-abi3-manylinux2010_x86_64
  cp34-abi3-manylinux1_x86_64
  cp34-abi3-linux_x86_64
  cp33-abi3-manylinux2014_x86_64
  cp33-abi3-manylinux2010_x86_64
  cp33-abi3-manylinux1_x86_64
  cp33-abi3-linux_x86_64
  cp32-abi3-manylinux2014_x86_64
  cp32-abi3-manylinux2010_x86_64
  cp32-abi3-manylinux1_x86_64
  cp32-abi3-linux_x86_64
  py38-none-manylinux2014_x86_64
  py38-none-manylinux2010_x86_64
  py38-none-manylinux1_x86_64
  py38-none-linux_x86_64
  py3-none-manylinux2014_x86_64
  py3-none-manylinux2010_x86_64
  py3-none-manylinux1_x86_64
  py3-none-linux_x86_64
  py37-none-manylinux2014_x86_64
  py37-none-manylinux2010_x86_64
  py37-none-manylinux1_x86_64
  py37-none-linux_x86_64
  py36-none-manylinux2014_x86_64
  py36-none-manylinux2010_x86_64
  py36-none-manylinux1_x86_64
  py36-none-linux_x86_64
  py35-none-manylinux2014_x86_64
  py35-none-manylinux2010_x86_64
  py35-none-manylinux1_x86_64
  py35-none-linux_x86_64
  py34-none-manylinux2014_x86_64
  py34-none-manylinux2010_x86_64
  py34-none-manylinux1_x86_64
  py34-none-linux_x86_64
  py33-none-manylinux2014_x86_64
  py33-none-manylinux2010_x86_64
  py33-none-manylinux1_x86_64
  py33-none-linux_x86_64
  py32-none-manylinux2014_x86_64
  py32-none-manylinux2010_x86_64
  py32-none-manylinux1_x86_64
  py32-none-linux_x86_64
  py31-none-manylinux2014_x86_64
  py31-none-manylinux2010_x86_64
  py31-none-manylinux1_x86_64
  py31-none-linux_x86_64
  py30-none-manylinux2014_x86_64
  py30-none-manylinux2010_x86_64
  py30-none-manylinux1_x86_64
  py30-none-linux_x86_64
  cp38-none-any
  py38-none-any
  py3-none-any
  py37-none-any
  py36-none-any
  py35-none-any
  py34-none-any
  py33-none-any
  py32-none-any
  py31-none-any
  py30-none-any
</code></pre>
<p>根据你的打印内容选择受支持的离线安装包</p>
<p>https://pypi.org/project/  在这里根据包名查包</p>
<p><img src="./pytorch-geometric%E5%AE%89%E8%A3%85/1672902124066.png" alt="1672902124066" /></p>
<h3 id="对numpy和torch进行简单调用"><a class="header" href="#对numpy和torch进行简单调用">对numpy和torch进行简单调用</a></h3>
<pre><code class="language-python">import torch as t
import numpy as n
a1 = t.ones(3,3)
a2 = t.ones(3,3)
b1 = n.ones((3,3))
b2 = n.ones((3,3))
print(a1+a2)
print(b1+b2)
</code></pre>
<p>输出</p>
<pre><code class="language-shell">[liyl@gpu-node1 torch]$ python3 test.py 
tensor([[2., 2., 2.],
        [2., 2., 2.],
        [2., 2., 2.]])
[[2. 2. 2.]
 [2. 2. 2.]
 [2. 2. 2.]]
</code></pre>
<h3 id="pyg"><a class="header" href="#pyg">pyG</a></h3>
<blockquote>
<p>pytorch-geometric简称pyG</p>
</blockquote>
<p>https://pytorch-geometric.com/whl/torch-1.13.0%2Bcpu.html</p>
<p>检索需要的版本</p>
<p>安装其他依赖：</p>
<pre><code class="language-bash">python3 -m pip install --user torch_scatter-2.1.0+pt113cpu-cp38-cp38-linux_x86_64.whl 
python3 -m pip install --user scipy-1.10.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl
python3 -m pip install --user torch_cluster-1.6.0+pt113cpu-cp38-cp38-linux_x86_64.whl
python3 -m pip install --user torch_sparse-0.6.16+pt113cpu-cp38-cp38-linux_x86_64.whl
python3 -m pip install --user torch_spline_conv-1.2.1+pt113cpu-cp38-cp38-linux_x86_64.whl
python3 -m pip install --user tqdm-4.64.1-py2.py3-none-any.whl
python3 -m pip install --user pytz-2022.7-py2.py3-none-any.whl
python3 -m pip install --user six-1.16.0-py2.py3-none-any.whl
python3 -m pip install --user python_dateutil-2.8.2-py2.py3-none-any.whl
python3 -m pip install --user pandas-1.5.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl
python3 -m pip install --user MarkupSafe-2.1.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl
python3 -m pip install --user Jinja2-3.1.2-py3-none-any.whl
python3 -m pip install --user certifi-2022.12.7-py3-none-any.whl
python3 -m pip install --user charset_normalizer-2.1.1-py3-none-any.whl
python3 -m pip install --user urllib3-1.26.13-py2.py3-none-any.whl
python3 -m pip install --user idna-3.4-py3-none-any.whl
python3 -m pip install --user requests-2.28.1-py3-none-any.whl
python3 -m pip install --user pyparsing-3.0.9-py3-none-any.whl
python3 -m pip install --user joblib-1.2.0-py3-none-any.whl
python3 -m pip install --user threadpoolctl-3.1.0-py3-none-any.whl
python3 -m pip install --user scikit_learn-1.2.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl
</code></pre>
<ul>
<li>
<p>从源码安装torch-geometric</p>
<p>pyG镜像链接</p>
</li>
</ul>
<p>https://mirrors.aliyun.com/pypi/simple/torch-geometric</p>
<pre><code class="language-shell">cd torch_geometric-2.0.4
python3 -m pip install . --user
</code></pre>
<p>测试能否导入成功</p>
<p><img src="./pytorch-geometric%E5%AE%89%E8%A3%85/1672967530424.png" alt="1672967530424" /></p>
<div style="break-before: page; page-break-before: always;"></div><p>date: 2022-11-27 11:11:18</p>
<p>tags: x11 xorg</p>
<pre><code class="language-c">#include &lt;X11/Xlib.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;unistd.h&gt;
int main()
{
    Display *dsp = XOpenDisplay(NULL);
    if (!dsp)
    {
        return 1;
    }
    int screenNumber = DefaultScreen(dsp);
    unsigned long white = WhitePixel(dsp, screenNumber);
    unsigned long black = BlackPixel(dsp, screenNumber);

    Window win = XCreateSimpleWindow(dsp,
                                     DefaultRootWindow(dsp), //parent
                                     50, 50,   // origin point
                                     400, 400, // size
                                     0, black, // border width and color
                                     white);   // backgd
    XMapWindow(dsp, win);
    Colormap screen_colormap = DefaultColormap(dsp, DefaultScreen(dsp));
    XColor red;
    int rc = XAllocNamedColor(dsp, screen_colormap, "red", &amp;red, &amp;red);
    // alloc color 'red' by its name
    if (rc == 0)
    {
        fprintf(stderr, "XAllocNamedColor - failed to allocated 'red' color.\n");
        exit(1);
    }

    GC gc = XCreateGC(dsp, win, 0, NULL);
    XSetForeground(dsp, gc, black);
    XDrawLine(dsp, win, gc, 10, 10, 190, 190); //draw a line with color black
    XFlush(dsp);
    sleep(1);
    XSetForeground(dsp, gc, red.pixel); // change color for next draw
    XDrawLine(dsp, win, gc, 210, 210, 390, 390); //draw a line with color red
    XFlush(dsp);
    getchar(); // shutdown key
    XDestroyWindow(dsp, win);
    XCloseDisplay(dsp);
    return 0;
}

</code></pre>
<p><img src="./x11-with-color/x11-color.jpg" alt="img" /></p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">

            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr.min.js"></script>
        <script src="mark.min.js"></script>
        <script src="searcher.js"></script>

        <script src="clipboard.min.js"></script>
        <script src="highlight.js"></script>
        <script src="book.js"></script>

        <!-- Custom JS scripts -->

        <script>
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>

    </div>
    </body>
</html>
